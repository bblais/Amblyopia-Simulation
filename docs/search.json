[
  {
    "objectID": "Treatment Models.html",
    "href": "Treatment Models.html",
    "title": "5  Models of Treatments for Amblyopia",
    "section": "",
    "text": "Code\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport plasticnet as pn\nimport process_images_hdf5 as pi5\nfrom deficit_defs import patch_treatment\n\nfrom matplotlib.pyplot import figure,xlabel,ylabel,legend,gca,plot,subplot,imshow,axis\nTo model the fix to the refractive imbalance we follow the deficit simulation with an input environment that is rebalanced, both eyes receiving nearly identical input patches (Figure 2.4). This process is a model of the application of refractive correction. Although both eyes receive nearly identical input patches, we add independent Gaussian noise to each input channel to represent the natural variation in the activity in each eye. In addition, in those cases where use employ strabismic amblyopia, the inter-eye jitter is not corrected with the refractive correction."
  },
  {
    "objectID": "Treatment Models.html#patch-treatment",
    "href": "Treatment Models.html#patch-treatment",
    "title": "5  Models of Treatments for Amblyopia",
    "section": "5.1 Patch treatment",
    "text": "5.1 Patch treatment\nThe typical patch treatment is done by depriving the strong-eye of input with an eye-patch. In the model this is equivalent to presenting the strong-eye with random noise instead of the natural image input. Competition between the left- and right-channels drives the recovery, and is produced from the difference between structured input into the weak-eye and the unstructured (i.e. noise) input into the strong eye. It is not driven by a reduction in input activity."
  },
  {
    "objectID": "Treatment Models.html#contrast-modification",
    "href": "Treatment Models.html#contrast-modification",
    "title": "5  Models of Treatments for Amblyopia",
    "section": "5.2 Contrast modification",
    "text": "5.2 Contrast modification\nA binocular approach to treatment can be produced with contrast reduction of the non-deprived channel relative to the deprived channel. Experimentally this can be accomplished with VR headsets(Xiao et al. 2020). In the model we implement this by down-scaling the normal, unblurred channel with a simple scalar multiplier applied to each pixel (Figure 4 D). The contrast difference sets up competition between the two channels with the advantage given to the weak-eye channel."
  },
  {
    "objectID": "Treatment Models.html#dichoptic-mask",
    "href": "Treatment Models.html#dichoptic-mask",
    "title": "5  Models of Treatments for Amblyopia",
    "section": "5.3 Dichoptic Mask",
    "text": "5.3 Dichoptic Mask\nOn top of the contrast modification, we can include the application of the dichoptic mask (Figure (fig:input?) E). In this method, each eye receives a version of the input images filtered through independent masks in each channel, resulting in a mostly-independent pattern in each channel.\nIt has been observed that contrast modification combined with dichoptic masks can be an effective treatment for amblyopia(xiao2021randomized?). The motivation behind the application of the mask filter is that the neural system must use both channels to reconstruct the full image and thus may lead to enhanced recovery.\nThe dichoptic masks are constructed with the following procedure. A blank image (i.e. all zeros) is made to which is added 15 randomly sized circles with values equal to 1 (Figure (fig:dichopic_blob?)). These images are then smoothed with a Gaussian filter of a given width, \\(f\\). This width is a parameter we can vary to change the overlap between the left- and right-eye images. A high value of \\(f\\) compared with the size of the receptive field, e.g. \\(f=90\\), yields a high overlap between the patterns in the weak- and strong-eye inputs (Figure (fig:dichopic_filter_size?)). Likewise, a small value of \\(f\\), e.g. \\(f=10\\), the eye inputs are nearly independent – the patterned activity falling mostly on one of the eyes and not much to both. Finally, the smoothed images are scaled to have values from a minimum of 0 to a maximum of 1. This image-mask we will call \\(A\\), and is the left-eye mask whereas the right-eye mask, \\(F\\), is the inverse of the left-eye mask, \\(F\\equiv 1-A\\). The mask is applied to an image by multiplying the left- and right-eye images by the left- and right-eye masks, respectively, resulting in a pair of images which have no overlap at the peaks of each mask, and nearly equal overlap in the areas of the images where the masks are near 0.5 (Figure (fig:dichopic_filter_image?))."
  },
  {
    "objectID": "Treatment Models.html#atropine-treatment",
    "href": "Treatment Models.html#atropine-treatment",
    "title": "5  Models of Treatments for Amblyopia",
    "section": "5.4 Atropine treatment",
    "text": "5.4 Atropine treatment\nIn the atropine treatment for amblyopia(Glaser et al. 2002), eye-drops of atropine are applied to the strong-eye resulting in blurred vision in that eye. Here we use the same blurred filter used to obtain the deficit (possibly with a different width) applied to the strong eye (Figure (fig:input?) F). The difference in sharpness between the strong-eye inputs and the weak-eye inputs sets up competition between the two channels with the advantage given to the weak-eye.\n\n\n\n\nGlaser, Stephen R, Andrea M Matazinski, David M Sclar, Nicholas A Sala, Chrissy M Vroman, Cindy E Tanner, David R Stager, et al. 2002. “A Randomized Trial of Atropine Vs Patching for Treatment of Moderate Amblyopia in Children.” Archives of Ophthalmology 120 (3): 268–78.\n\n\nLi, Simone L, Alexandre Reynaud, Robert F Hess, Yi-Zhong Wang, Reed M Jost, Sarah E Morale, Angie De La Cruz, Lori Dao, David Stager Jr, and Eileen E Birch. 2015. “Dichoptic Movie Viewing Treats Childhood Amblyopia.” J AAPOS 19 (5): 401–5. https://doi.org/10.1016/j.jaapos.2015.08.003.\n\n\nXiao, Scott, Eric D Gaier, Malcolm L Mazow, Ann U Stout, Dean A Travers, Endri Angjeli, Hank C Wu, Gil Binenbaum, and David G Hunter. 2020. “Improved Adherence and Treatment Outcomes with an Engaging, Personalized Digital Therapeutic in Amblyopia.” Scientific Reports 10 (1): 1–8."
  },
  {
    "objectID": "Synaptic Modification.html",
    "href": "Synaptic Modification.html",
    "title": "3  Synaptic Modification",
    "section": "",
    "text": "Code\n%matplotlib inline\nfrom input_environment_defs import *\nfrom deficit_defs import Results"
  },
  {
    "objectID": "Synaptic Modification.html#the-bcm-learning-rule",
    "href": "Synaptic Modification.html#the-bcm-learning-rule",
    "title": "3  Synaptic Modification",
    "section": "3.1 The BCM Learning Rule",
    "text": "3.1 The BCM Learning Rule\nWe use a single neuron and the parabolic form of the BCM(Bienenstock, Cooper, and Munro 1982; Brian S. Blais et al. 2008) learning rule for all of the simulations, where the synaptic modification depends on the postsynaptic activity, \\(y\\), in the following way for a single neuron\n\\[\ny=\\sigma\\left(\\sum_i x_i w_i \\right)\n\\] \\[\n\\frac{dw_i}{dt} = \\eta y(y-\\theta_M) x_i\n\\] \\[\n\\frac{d\\theta_M}{dt} = (y^2-\\theta_M)/\\tau\n\\]\nwhere is \\(x_i\\) is the \\(i\\)th presynaptic input, \\(w_i\\) is the \\(i\\)th synaptic weight, and \\(y\\) is the postsynaptic output activity. The constant, \\(\\eta\\), refers to the learning rate and the constant, \\(\\tau\\), is what we call the memory-constant and is related to the speed of the sliding threshold. The transfer function, \\(\\sigma(\\cdot)\\), places minimum and maximum responses given a set of inputs and weights.\n\n\nCode\ny=np.linspace(-5,20,100)\nθ_M=8\nϕ=y*(y-θ_M)\n\nplot(y,ϕ,'b-')\n\nyl=gca().get_ylim()\nplot([0,0],yl,'k--')\ngca().set_ylim(yl)\n\nxl=gca().get_xlim()\nplot(xl,[0,0],'k--')\ngca().set_xlim(xl)\n\nplt.text(θ_M,30,r'$\\theta_M$',ha='center',va='center')\nplt.arrow(θ_M+1,30,5,0,color='r',length_includes_head=True,\n              head_width=5, head_length=.6,lw=2)\nplt.arrow(θ_M-1,30,-5,0,color='r',length_includes_head=True,\n              head_width=5, head_length=.6,lw=2)\nplot([θ_M,θ_M],[-10,10],'r-',lw=2)\nxlabel('Neuron output ($y$)')\nylabel('Change in the synaptic weight ($dw/dt$)');\n\n\n\n\n\nFigure 3.1: The BCM synaptic modification function. Units are arbitrary.\n\n\n\n\nThe results are extremely robust to values of \\(\\eta\\) and \\(\\tau\\) , which are generally chosen for practical, rather than theoretical, considerations. Each of these constants is related to the time-step for the simulations, but given the phenomenological nature of the BCM theory it is beyond the scope of this paper to make detailed comparisons between simulation time and real-time. Further, the fact that \\(\\tau\\) can be changed within a factor of 100 with no noticeable effect, the experiments presented here cannot be used address the time-scales of the molecular mechanisms underlying synaptic modification. Whenever we refer to real-time units for a simulation, we approximate a single simulation iteration as 1 iteration = 0.2 seconds(Brian S. Blais 1998).\nIn the BCM learning rule, weights decrease if \\(y\\) is less than the modification threshold,\\(\\theta_M\\) , and increase if \\(y\\) is greater than the modification threshold. To stabilize learning, the modification threshold “slides” as a super-linear function of the output. The output, \\(y\\) , is related to the product of the inputs and the weights via a sigmoidal function, \\(\\sigma(\\cdot)\\), which places constraints on the values of the output, keeping it in the range -1 and 50. The interpretation of negative values is consistent with previous work(B. S. Blais et al. 1998), where the activity values are measured relative to spontaneous activity. Thus, negative values are interpreted as activity below spontaneous. We continue this usage, in order to more easily compare with previous simulations. The role of the spontaneous level for the simulations in the natural image environment is discussed elsewhere(B. S. Blais et al. 1998)."
  },
  {
    "objectID": "Synaptic Modification.html#simulation",
    "href": "Synaptic Modification.html#simulation",
    "title": "3  Synaptic Modification",
    "section": "3.2 Simulation",
    "text": "3.2 Simulation\nThe synaptic weights, and the modification threshold, are set to small random initial values at the beginning of a simulation. At each iteration, an input patch is generated as described above depending on the procedure being simulated and then presented to the neuron. After each input patch is presented, the weights are modified using the output of the neuron, the input values and the current value of the modification threshold. In an input environment composed of patches taken from natural images, with equal patches presented to the left- and right-eyes as shown in Figure 2.4, this process orientation selective and fully binocular cells(B. S. Blais et al. 1998). We then present test stimulus made from sine-gratings with 24 orientations, 20 spatial frequencies, and optimized over phase. Applying any of the blur filters to the sine gratings does not quantitatively change the result.\n\n\nCode\nfname=pi5.filtered_images('asdf/bbsk081604_all_log2dog.asdf')\n\npre1=pn.neurons.natural_images(fname,\n                               rf_size=19,verbose=False)\n\npre2=pn.neurons.natural_images(fname,rf_size=19,\n                            other_channel=pre1,\n                            verbose=False)\n\npre1+=pn.neurons.process.add_noise_normal(0,0.5) # a little noise\npre2+=pn.neurons.process.add_noise_normal(0,0.5) # a little noise\n\n\npre=pre1+pre2\n\nnumber_of_neurons=5\npost=pn.neurons.linear_neuron(number_of_neurons)\npost+=pn.neurons.process.sigmoid(0,50)\n\nc=pn.connections.BCM(pre,post,[-.01,.01],[.1,.2])\nc+=pn.connections.process.orthogonalization(10*minute)\nc.eta=2e-6\nc.tau=15*minute   \n\nsim=pn.simulation(4*day)\nsim.dt=200*ms\n\nsave_interval=30*minute\nsim.monitor(post,['output'],save_interval)\nsim.monitor(c,['weights','theta'],save_interval)\n\nsim+=pn.grating_response()\n\npn.run_sim(sim,[pre,post],[c],display_hash=True,print_time=True)\npn.save('sims/nr.asdf',sim,[pre,post],[c])\nR=Results('sims/nr.asdf')\n\n\n\n\nCode\ndef argmax_rc(X):\n    \"\"\"Return the row and col of the maximum value\"\"\"\n    r,c=np.unravel_index(np.argmax(X), X.shape)\n    return r,c\n\n\n\n\nCode\nfigure(figsize=(4,10))\nR.plot_rf()\n\nfigure(figsize=(10,8))\nplot(R.t/hour,R.θ,label=[f'Neuron {i}' for i in [0,1,2,3,4]])\nylabel(r'$\\theta_M$')\nxlabel('Time (hours)')\nlegend();\n\nfigure(figsize=(10,8))\nt,y=R.all_responses[0]\nfor neuron in range(5):\n    subplot(2,1,1)\n    y_left=y[:,:,0,neuron,-1]  \n    y_right=y[:,:,1,neuron,-1]  \n    \n    r,c=argmax_rc(y_left)\n    tuning_curve=y_left[r,:]    \n    plot(R.theta_mat,tuning_curve,'-o')\n    plt.title('Left-eye Responses')\n    ylabel('Response')\n    gca().set_xticklabels([])\n    \n    subplot(2,1,2)\n    r,c=argmax_rc(y_right)\n    tuning_curve=y_right[r,:]\n    plot(R.theta_mat,tuning_curve,'-s')    \n    plt.title('Right-eye Responses')\n    ylabel('Response')\n    xlabel('Angle of Stimulus')\n    \n\n\n\n\n\n\n\n\n(a) Synaptic weights where black denotes weak weights and white denotes strone weights. A clear preference for oriented stimuli can be seen.\n\n\n\n\n\n\n\n(b) BCM modification threshold over time. The value converges to nearly the same level for all neurons.\n\n\n\n\n\n\n\n\n\n(c) Responses to Oriented Stimuli after training. Each neuron develops orientation selectivity to a range of optimum angles.\n\n\n\n\nFigure 3.2: Simulation of 5 neurons receiving identical natural image patterns into the left- and right-input channels.\n\n\n\n\n\n\n\nBienenstock, E. L., L. N Cooper, and P. W. Munro. 1982. “Theory for the Development of Neuron Selectivity: Orientation Specificity and Binocular Interaction in Visual Cortex.” Journal of Neuroscience 2: 32–48.\n\n\nBlais, B. S., N. Intrator, H. Shouval, and L. N Cooper. 1998. “Receptive Field Formation in Natural Scene Environments: Comparison of Single Cell Learning Rules.” Neural Computation 10 (7): 1797–1813.\n\n\nBlais, Brian S. 1998. “The Role of the Environment in Synaptic Plasticity:\ntowards an Understanding of Learning and Memory.” PhD thesis, Brown University, Institute for Brain; Neural Systems; Dr. Leon N Cooper, Thesis Supervisor.\n\n\nBlais, Brian S, Mikhail Y Frenkel, Scott R Kuindersma, Rahmat Muhammad, Harel Z Shouval, Leon N Cooper, and Mark F Bear. 2008. “Recovery from Monocular Deprivation Using Binocular Deprivation.” J Neurophysiol 100 (4): 2217–24. https://doi.org/10.1152/jn.90411.2008."
  },
  {
    "objectID": "Deficit Models.html",
    "href": "Deficit Models.html",
    "title": "4  Models of Development of Amblyopia",
    "section": "",
    "text": "Code\n%matplotlib inline\nfrom input_environment_defs import *\nAmblyopia is a reduction of the best-corrected visual acuity (BCVA) with an otherwise normal eye and has many causes(Wallace et al. 2018). Two of the most common forms of amblyopia are strabismic and anisometropic amblyiopia. Strabismic amblyopia occurs when the inputs from each eye do not converge and the fixating eye becomes dominant over a non-fixating eye. Refractive amblyopia occurs with untreated unilateral refractive errors, one kind being anisometropic amblyopia where unequal refractive power in each eye leads the retinal image from the amblyopic eye to be blurred relative to the fellow eye. Both of these processes lead to synaptic plasticity adjustments and interocular competition, enhancing the initial deficit.\nIn this work we use a model of the amblyopic deficit caused by two mechanisms. The first is a blurring of the amblyopic eye inputs, representing refractive amblyopia. The second is eye-jitter, representing one source of strabismic amblyopia. We can explore these mechanisms independently and in conjunction to see how they respond differentially to the various treatments."
  },
  {
    "objectID": "Deficit Models.html#refractive-amblyopia",
    "href": "Deficit Models.html#refractive-amblyopia",
    "title": "4  Models of Development of Amblyopia",
    "section": "4.1 Refractive amblyopia",
    "text": "4.1 Refractive amblyopia\nThe amblyopic eye is presented with image patches that have been blurred with a normalized Gaussian filter applied to the images with a specified width. The larger the width the blurrier the resulting filtered image.\n\n\nCode\nsim,X=get_input_patch_examples(blur=2.5)\nims=inputs_to_images(X,buffer=2)\nfigure(figsize=(20,6))\nfor i in range(24):\n    im=ims[i]\n    subplot(4,6,i+1)\n    imshow(im,cmap=plt.cm.gray)\n    axis('off')\n    \n\n\n\n\n\nFigure 4.1: A sample of 24 input patches from a refractive amblyopic environment. The amblyopic (blurred) input is the square on the left-hand side of each pair."
  },
  {
    "objectID": "Deficit Models.html#strabismic-amblyopia",
    "href": "Deficit Models.html#strabismic-amblyopia",
    "title": "4  Models of Development of Amblyopia",
    "section": "4.2 Strabismic amblyopia",
    "text": "4.2 Strabismic amblyopia\nStrabismic inputs are modeled by changing the center of the left- and right-input patches in a systematic way, with a set mean offset and a standard deviation per input patch generated. In this way we can model completely overlapping (i.e. normal) inputs, completely non-overlapping (i.e. extreme strabismus), and any amount of overlap in between. Some examples are shown in Figure 4.2 with the offset locations shown in Figure 4.3.\n\n\nCode\nmu_r,mu_c=2,10\nsigma_r,sigma_c=1,2\n\nsim,X=get_input_patch_examples_with_jitter(blur=-1,mu_r=mu_r,mu_c=mu_c,sigma_r=sigma_r,sigma_c=sigma_c)\nims=inputs_to_images(X,buffer=2)\nfigure(figsize=(20,6))\nfor i in range(24):\n    im=ims[i]\n    subplot(4,6,i+1)\n    imshow(im,cmap=plt.cm.gray)\n    axis('off')\n    \n\n\n\n\n\nFigure 4.2: A sample of 24 input patches from a strabismic visual environment achieved through random jitter of the amblyopic (left) eye.\n\n\n\n\n\n\nCode\nimport matplotlib.patches as patches\nca=sim.monitors['ca'].array()\nra=sim.monitors['ra'].array()\nc=sim.monitors['c'].array()\nr=sim.monitors['r'].array()\n\nca_1=sim.monitors['ca_1'].array()\nra_1=sim.monitors['ra_1'].array()\nc_1=sim.monitors['c_1'].array()\nr_1=sim.monitors['r_1'].array()\n\nfigure(figsize=(11,9))\nplot(ca-c,-(ra-r),'bo',label='Left')\n\nplot(ca_1-c_1,-(ra_1-r_1),'ro',label='Right')\nrect = patches.Rectangle((-19/2, -19/2), 19, 19, linewidth=1, edgecolor='b',lw=2, facecolor='gray',alpha=0.5)\ngca().add_patch(rect)\nrect = patches.Rectangle((-19/2+mu_c, -19/2-mu_r), 19, 19, linewidth=1, edgecolor='r', lw=2,facecolor='gray',alpha=0.5)\ngca().add_patch(rect)\naxis('equal');\n\nxlabel('Horizontal Visual Field Location (pixels)')\nylabel('Vertical Visual Field Location (pixels)');\nlegend();\n\n\n\n\n\nFigure 4.3: Locations of the center of the left- and right-field of view receptive fields, jittered randomly with set mean and standard deviation. The average receptive fields are shown as gray squares.\n\n\n\n\n\n\n\n\nWallace, David K, Michael X Repka, Katherine A Lee, Michele Melia, Stephen P Christiansen, Christie L Morse, and Derek T Sprunger. 2018. “Amblyopia Preferred Practice Pattern.” Ophthalmology 125 (1): P105–42."
  }
]