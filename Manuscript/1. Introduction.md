# Introduction

In this introduction, I want to be clear about as many of the underlying assumptions being made and to highlight where the various results come from in the simulations.   By comparing low-dimension and high-dimension environments, it's my hope that it will make clearer what sorts of changes to the input environment will lead to particular dynamics of synaptic plasticity.  Building up one's intuition this way should help in proposing alternate treatments for amblyopia and understanding how the parameters of those treatments affect their outcomes. 

## The Neuron

The BCM theory[@BCM82] of synaptic plasticity starts with a simplified model of a neuron shown in [Figure @fig:simple_neuron].  In the figure, the model of the neuron has 4 inputs denoted as $x_1, x_2, x_3,$ and $x_4$.  These inputs are connected to the cell via 4 synaptic weights, denoted as $w_1, w_2, w_3,$ and $w_4$.  The output of the cell, $y$, is given as a sum of the input values each multiplied by the synaptic weight connecting it to the neuron passed through an output function, often a sigmoid, $\sigma$:
$$
y=\sigma\left(\sum_i x_i w_i \right)
$$
In this simple model, the value of neural activity $x_i=0$ or $y=0$ refers to *spontaneous activity*, thus one can have negative values for this activity representing *below spontaneous* activity.  The sigmoid function is chosen to have the effect of limiting the spontaneous level of activity, i.e. the neuron has a larger range of activity above spontaneous than below it.

The synapse values, $w_i$, may represent the combination of several synapses -- including inhibitory synapses -- which implies that the weights can take on both positive and negative values.   The number of inputs (4 in the case of  [Figure @fig:simple_neuron]) is arbitrary and will be different from one environment to another.  What is called a "low-dimensional" environment is one with few inputs, likewise a "high-dimensional" environment will have many (possibly hundreds).

![[Simple Neuron.pdf]]
>Simple model of a neuron with 4 inputs ($x_1, x_2, x_3,$ and $x_4$), connecting to the cell via 4 synaptic weights ($w_1, w_2, w_3,$ and $w_4$), yielding an output ($y$).{#fig:simple_neuron}

## Plasticity

The BCM theory states that the synaptic weights change depending on the input to those weights, the output of the neuron, and a sliding threshold according to the following equations,
$$
\frac{dw_i}{dt} = \eta y(y-\theta_M) x_i
$${#eq:bcm1}


$$
\frac{d\theta_M}{dt} = (y^2-\theta_M)/\tau
$${#eq:bcm2}

where is $x_i$ is the $i$th  presynaptic input, $w_i$  is the $i$th synaptic weight, and $y$ is the postsynaptic output activity.  In [Equation @eq:bcm1], the weights increase if the output, $y$, is above the threshold, $\theta_M$, and decrease if the output is below the threshold. The sliding threshold, $\theta_M$, follows postsynaptic activity in a non-linear way ([Equation @eq:bcm2]) and serves to stabilize any runaway weights and the combination of the two equations enforces the selectivity property of the BCM neuron[@phd:Blais98].  The constant, $\eta$, refers to the learning rate and the constant, $\tau$, is what we call the memory constant and is related to the speed of the sliding threshold.  These parameters influence the overall rate of synaptic plasticity and are generally held constant for any series of simulations so that relative dynamics can be compared.


The form of the BCM equations is what is called the *quadratic form* and represents the simplest way of writing the minimum requirements of the BCM theory, but other forms have also been explored[@IntratorCooper92; @LawCooper94].   

![[fig-bcm-phi.svg]]
>The BCM synaptic modification function.  Units are arbitrary.


## Selectivity

One of the properties of the BCM learning rule is that in most environments the neuron becomes *selective* -- it responds to a small subset of the environment and has low or zero responses to the rest of the environment.   We can see this by looking at the response of the neuron, $y$, across the entire environment.  Imagine that there are two possible patterns:

1. input #1 is *strongly* active and input #2 is weakly active
2. input #2 is *strongly* active and input #1 is weakly active

At the start, the BCM neuron responds strongly to both patterns about the same amount of time.  After learning, the BCM becomes selective -- it responds to only one of the patterns strongly most of the time, and the other pattern yields a weak response as shown in [Figure @fig:output_dist_2d].  This distribution is *bimodal* -- there is a cluster of responses above zero and one below zero, separated by a gap of no responses.  When we think of selective responses we often think in terms of bimodal output distributions.  We will see later that this is not a general property of selective responses, however it is an intuitive way of thinking about them.

![[Pasted image 20240123131156.png]]
>The output distribution for a BCM neuron.  The initial distribution (above) shows that the BCM neuron responds strongly to both patterns about the same amount of time.  The final distribution (below) shows that the BCM neuron responds to only one of the patterns strongly most of the time, and the other pattern yields a weak response.  This distribution is *bimodal* -- there is a cluster of responses above zero and one below zero, separated by a gap of no responses.  Also notice that the modification threshold, $\theta_M$, settles on the value of the neural output for the selected pattern.  {#fig:output_dist_2d} 

Geometrically we can plot the input patterns by plotting the activity of input #1 on the x-axis and the activity of input #2 on the y-axis -- this shows 2 primary clusters, as shown in [Figure @fig:2d_inputs].  

We can also show the values of the weights as a "dot" on this plot, with the weight for input #1 on the x-axis and the weight for input #2 on the y-axis.  Visually, it is easier to see it by drawing a line from the origin to this dot.  The output distribution is formed by projecting a perpendicular from the inputs to this line, as shown in [Figure @fig:2d_initial_weights_outputs] for the initial weights and [Figure @fig:2d_final_weights_outputs] for the final weights.  Geometrically, for the weights to have weak responses to an input pattern then the weights must be *perpendicular to that input pattern*.  One can see this for the final weights and pattern #2 in these figures.

![[Pasted image 20240123130523.png]]
> 2D input environment.  {#fig:2d_inputs}.

![[Pasted image 20240123130539.png]]
> Geometric interpretation of the weights and output distributions for the *initial weights* in a 2D input environment.  {#fig:2d_initial_weights_outputs}.

![[Pasted image 20240123130559.png]]
> Geometric interpretation of the weights and output distributions for the *final weights* in a 2D input environment.  {#fig:2d_final_weights_outputs}

## Natural Images


![[weights and output distribution natural images.drawio.png]]
> Weights (A) and Output distributions (B) for 12 neurons trained with natural image input patterns.  The weights are shown in grayscale, with black representing low weights and white representing high weights.  The output distribution is shown on a log scale to highlight the few patterns that yield the strongest responses.   {#fig:nat_image_weights_and_output_dist}

Shown in [Figure @fig:nat_image_weights_and_output_dist] are the weights and output distributions for 12 neurons trained with natural image input patterns.  We easily see that the neurons are selective to orientation -- the final weights are organized in a line at a particular orientation.  Thus, any input pattern that has that same orientation will elicit stronger responses because the pattern will align with the strong weights.  Unlike the low dimensional case earlier, the output distributions for each neuron is *not bimodal*.  The output distribution does not show a cluster above zero and a cluster at zero with a gap in between, it is smeared out over the entire range of the responses.  What makes the neuron selective is the fact that the vast bulk of the responses are near zero, and while there is no gap between low and high responses, the number of patterns yielding strong responses is very small.  Note that the output distributions are being shown on a log scale, otherwise those strong responses would not even be visible.  

This observation means that what BCM neurons select in an environment is not always *clusters* but a small number of patterns in a sea of similar patterns.  Statistically, this means that BCM is sensitive to statistics in the input environment beyond separability and 2-point correlations[@brito2024learning].  In order to understand the dynamics of BCM neurons we can explore environments with patterns that don't fall into neat clusters but instead are spread out with higher order statistics.