# Normal and Deprived Visual Environments

In order to approximate the visual system, we start with the following basic properties of the retina, LGN and cortex. There are approximately 1000 photoreceptors feeding into 1 ganglion cell [@JeonEtAl1998;@SterlingEtAl1988]. The retina/LGN responses show a center-surround organization, but with a center diameter less than 1$^o$ [@hubel1995eye]

We use natural scene stimuli for the simulated inputs to the visual system. We start with images taken with a digital camera, with dimensions 1200 pixels by 1600 pixels and 40$^o$ by 60$^o$ real-world angular dimensions ([Figure @fig:natural_images]). We model the light adaption of the photoreceptors[@bonin2005suppressive;@carandini2012normalization] where the responses reflect the contrast (i.e. difference from the mean, $I_m$) and normalized to the standard deviation of the pixel values, $I_\sigma$, 

$$
R=\frac{I-I_m}{I_\sigma}
$$
Finally, we model the contrast normalization and the suppressive field of the ganglion responses using a 32x32 pixel center-surround difference-of-Gaussians (DOG) filter to process the images ([Figure @fig:normal_vision_model]). The center-surround radius ratio used for the ganglion cell is 1:3, with balanced excitatory and inhibitory regions and normalized Gaussian profiles.   Even in the normal visual environment we explore the role of eye-jitter, where the locations of the left- and right-receptive fields are chosen to deviate from a common center by an average shift, $\mu_c$, and variation, $\sigma_c$ (see [Figure @fig:eye_jitter]). 


![[Pasted image 20240301091111.png]]
> Natural Image Environment. {#fig:natural_images}


![[Pasted image 20240301091213.png]]
> Normal Vision Model. {#fig:normal_vision_model}

![[Pasted image 20240301091231.png]]
> Model of Eye Jitter. {#fig:eye_jitter}


### Two-eye architecture

Shown in [Figure @fig:arch] is the visual field, approximated here as a two-dimensional projection, to left and right retinal cells. These left and right retinal cells project to the left and right LGN cells, respectively, and finally to a single cortical cell. The LGN is assumed to be a simple relay, and does not modify the incoming retinal activity.  It is important to understand that the model we are pursuing here is a *single cortical cell* which receives input from both eyes.  We will encounter some limitations to this model which may necessitate exploring multi-neuron systems.  

In the model, normal development is simulated with identical image patches presented to both eyes combined with small independent noise in each eye.  The random noise is generated from a zero-mean normal distribution of a particular variance, representing the natural variation in responses of LGN neurons. Practically, the independent random noise added to each of the two-eye channels avoids the artificial situation of having mathematically identical inputs in the channels.  The development of the deficit and the subsequent treatment protocols are modeled with added preprocessing to these image patches, described below in Section @sec:models-of-development-and-treatment-of-amblyopia.

For all of the simulations we use a 19 pixel x 19 pixel receptive field, which is a compromise between speed of simulation and the limits of spatial discretization.  We perform at least 20 independent simulations for each condition to address variation in the results.



![[Pasted image 20240301091247.png]]
> Architecture for binocular neurons in natural image environment. {#fig:arch}


## Ocular Dominance Index

Simulations are ended when selectivity has been achieved and the responses are stable. From the maximal responses of each eye, $R_{\text{left}}$ and $R_{\text{right}}$, individually, we can calculate the ocular dominance index as
$$
\text{ODI} \equiv \frac{R_{\text{right}}-R_{\text{left}}}{R_{\text{right}}+R_{\text{left}}}
$$
The ocular dominance index (ODI) has a value of $\text{ODI} \approx 1$ when stimulus to the right-eye (typically the fellow-eye in the simulations, by convention) yields a maximum neuronal response with little or no contribution from the left-eye.  Likewise, an ocular dominance index (ODI) has a value of $\text{ODI} \approx -1$ when stimulus to the left-eye (typically the amblyopic-eye, by convention) yields a maximum neuronal response with little or no contribution from the right-eye.  A value of $\text{ODI} \approx 0$ represents a purely binocular cell, responding equally to stimulus in either eye.

Recovery and deprivation speed is measured in ODI shift over the time of simulation, with the units of time are arbitrary.  This allows us to compare different treatment protocols and examine how the rates of deprivation vary based on the simulation and environment parameters. 

## Models of Deprivation





## Models of Development and Treatment of Amblyopia

Here we explore the model environments for the initial deficit and the treatments.  Amblyopia is achieved by an imbalance in right and left inputs, and treated with a re-balance or a counter-balance of those inputs (e.g. patching the dominant eye).  In this work, we model the initial deficit as resulting from an asymmetric *blurring* of the visual inputs, as would be produced by a refractive difference between the eyes ([Figure fig:vision_deficit_model]).  The amblyopic eye is presented with image patches that have been *blurred* with a normalized Gaussian filter applied to the images with a specified width.  The larger the width the blurrier the resulting filtered image.  Using a blur filter size of 2.5 pixels produces a robust deficit in the simulations, and thus we use this deficit as the starting point for all of the treatment simulations.   Although both eyes receive nearly identical input patches, we add independent Gaussian noise to each input channel to represent the natural variation in the activity in each eye.  

In addition to the refractive deficit we also model a strabismic jitter in the input pattern, represented as a pixel-shift of the input column and row with means $\mu_c$ and $\mu_r$, respectively, with standard deviations $\sigma_c$ and $\sigma_r$, respectively.  For example, in the simple case of $\mu_c=\mu_r=0$ and $\sigma_c=\sigma_r=0$ the eye inputs are identical (up to intrinsic noise).   If $\mu_c=5$ then the input images for the two channels are shift left-right by a constant 5 pixels.  If $\mu_c>19$ (with 19 being the receptive field size), then the eyes will see completely non-overlapping areas of the image.  

To model the optical fix to the refractive imbalance we follow the deficit simulation with an input environment that is rebalanced, both eyes receiving nearly identical input patches ([Figure @fig:optical_fix_mode]).   This process is a model of the application of glasses.  The optical fix will remove the refractive deficit but will not treat any strabismic jitter. 


### Patch treatment

The typical patch treatment is done by depriving the fellow-eye of input with an eye-patch.  In the model this is equivalent to presenting the fellow-eye with random noise instead of the natural image input ([Figure @fig:patch_model]).  Competition between the left- and right-channels drives the recovery, and is produced from the difference between *structured* input into the amblyopic-eye and the *unstructured* (i.e. noise) input into the fellow-eye.  It is not driven by a reduction in input activity.  As shown in @sec:results, increased *unstructured* input into the previously dominant eye increases the rate of recovery.  This is a general property of the BCM learning rule and has been explored in [Section @sec:structure-vs-noise].


### Atropine treatment

In the atropine treatment for amblyopia[@glaser2002randomized], eye-drops of atropine are applied to the fellow-eye resulting in blurred vision in that eye.  Here we use the same blurred filter used to obtain the deficit (possibly with a different width) applied to the fellow eye ([Figure @fig:atropine_model]) along with an additional amount of noise.  The difference in sharpness between the fellow-eye inputs and the amblyopic-eye inputs sets up competition between the two channels with the advantage given to the amblyopic-eye.

### Contrast modification

A binocular approach to treatment can be produced with contrast reduction of the non-deprived channel relative to the deprived channel. Experimentally this can be accomplished with VR headsets[@xiao2020improved]. In the model we implement this by transforming the image toward the average proportional to a simple scalar contrast value,
$$
I_{\text{new}} = I_{\text{orig}} \cdot \text{constrast} + I_m\cdot(1-\text{contrast})
$$
where $I_m$ is an image consisting of a single uniform gray value of the average of the original image, $I_{\text{orig}}$.  When $\text{constrast}=1$ there is no transformation, whereas a value of $\text{constrast}=0$ results in the image replaced with a uniform gray value of the mean image, $I_m$ ([Figure @fig:contrast_mask_model]). The contrast difference sets up competition between the two channels with the advantage given to the amblyopic-eye channel.

### Dichoptic Mask

On top of the contrast modification, we can include the application of the dichoptic mask ([Figure @fig:contrast_mask_model]).  In this method, each eye receives a version of the input images filtered through independent masks in each channel, resulting in a mostly-independent pattern in each channel.   It has been observed that contrast modification combined with dichoptic masks can be an effective treatment for amblyopia[@Li:2015aa,@xiao2022randomized].  The motivation behind the application of the mask filter is that the neural system must use both channels to reconstruct the full image and thus may lead to enhanced recovery.  

The dichoptic masks are constructed with the following procedure.  A blank image (i.e. all zeros) is made to which is added 15 randomly sized circles with values equal to 1 ([Figure @fig:dichopic_blob]).   These images are then smoothed with a Gaussian filter of a given width, $f$.  This width is a parameter we can vary to change the overlap between the left- and right-eye images.  A high value of $f$ compared with the size of the receptive field, e.g. $f=90$, yields a high overlap between the patterns in the amblyopic- and fellow-eye inputs ([Figure @fig:dichopic_filter_size]).  Likewise, a small value of $f$, e.g. $f=10$, the eye inputs are nearly independent -- the patterned activity falling mostly on one of the eyes and not much to both.  Finally, the smoothed images are scaled to have values from a minimum of 0 to a maximum of 1.  This image-mask we will call $A$, and is applied to left-eye whereas the right-eye mask, $F$, is the inverse of the left-eye mask, $F\equiv 1-A$.  The mask is applied to an image by weighting original image and the uniform gray value average, $I_m$, by the strength of the mask. ,

$$
\begin{aligned}
I_{\text{left}} &= I_{\text{orig}} \cdot A + I_m\cdot(1-A) \\
I_{\text{right}} &= I_{\text{orig}} \cdot F + I_m\cdot(1-F)
\end{aligned}
$$
resulting in a pair of images which have no overlap at the peaks of each mask, and nearly equal overlap in the areas of the images where the masks are near 0.5 ([Figure @fig:dichopic_filter_image]).   



![[Pasted image 20240301091305.png]]
> Vision Deficit Model. {#fig:vision_deficit_model}

![[Pasted image 20240301091503.png]]
> Optical Fix Model.  {#fig:optical_fix_model}

![[Pasted image 20240301091523.png]]
> Patch Model. {#fig:patch_model}

![[Pasted image 20240301091538.png]]
> Atropine Model. {#fig:atropine_model}

![[Pasted image 20240301091600.png]]
> Contrast/Mask Model. {#fig:contrast_mask_model}



![[blob_convolution_example_fsig_20.png]]
> Mask from blob.  {#fig:dichopic_blob}

![[mask_filter_examples_fsigs.png]]
> Mask filter size. {#fig:dichopic_filter_size}

![[mask_filter_example_fsig_20.png]]
> Masked image example. {#fig:dichopic_filter_image}